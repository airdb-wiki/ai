{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction 翻译 Machine Learning With Go Machine Learning With Go PDF: Machine Learning With Go Source Code 机器学习 - Go Copyright © 2015-present airdb.            LastUpdated: 2020-01-12 05:24:59 "},"wiki/":{"url":"wiki/","title":"Wiki","keywords":"","body":"算法 机器学习算法有很多，大概有，回归算法、基于实例的算法、正则化算法、决策树算法、贝叶斯算法、基于核的算法、聚类算法、关联规则学习、人工神经网络算法、深度学习算法、降低维度算法、集成算法，下面将几个常见的机器学习算法，进行详述： 决策树算法，根据数据的属性采用树状结构建立决策模型$常常用来解决分类和回归问题。 优点：计算量比较简单，解释性强，比较适合处理有缺失属性值的数据样本，能够处理不相关的特征。 缺点：容易过拟合（后续出现了随机森林，减小了过拟合现象）。 贝叶斯算法，基于贝叶斯定理的一类算法，主要用来解决分类和回归问题。 优点：对小规模的数据表现很好，适合多分类任务，适合增量式训练。 缺点：对输入数据的表达形式很敏感，对关联性强的特征表现不好。 朴素贝叶斯分类 https://www.zhihu.com/question/27306416 算法模型 回归算法 线性回归 逻辑回归 多元自适应回归(MARS) 本地散点平滑估计(LOESS) 基于实例的学习算法 K-邻近算法（KNN） 学习矢量化（LVQ） 自组织映射算法（SOM） 局部加权学习算法（LWL） 正则化算法 岭回归（Ridge Regression） LASSO（Least Absolute Shrinkage and Selection Operator） Elastic Net 最小角回归（LARS） 决策树算法 分类和回归树（CART） ID3算法(Iterative Dichotomiser 3) CHAID（Chi-squared Automatic Interaction Detection 随机森林（Random Forest） 多元自适应回归样条（MARS） 梯度推进机（Gradient Boosting Machine， GBM） 贝叶斯算法 朴素贝叶斯 高斯朴素贝叶斯 多项式朴素贝叶斯 AODE（Averaged One-Dependence Estimators） 贝叶斯网络（Bayesian Belief Network） 基于核的算法 支持向量机（SVM） 径向基函数（Radial Basis Function ，RBF) 线性判别分析（Linear Discriminate Analysis ，LDA) 聚类算法 K-均值 K-中位数 EM算法 分层聚类 关联规则学习 Apriori算法 Eclat算法 神经网络 感知器 反向传播算法（BP） Hopfield网络 径向基函数网络（RBFN） 深度学习 深度玻尔兹曼机（DBM） 卷积神经网络（CNN） 递归神经网络（RNN、LSTM） 栈式自编码算法（Stacked Auto-Encoder） 降维算法 主成分分析法（PCA） 主成分回归（PCR） 偏最小二乘回归（PLSR） 萨蒙映射 多维尺度分析法（MDS 投影寻踪法（PP） 线性判别分析法（LDA） 混合判别分析法（MDA） 二次判别分析法（QDA） 灵活判别分析法（Flexible Discriminant Analysis，FDA 集成算法 Boosting Bagging AdaBoost 堆叠泛化（混合） GBM 算法 GBRT 算法 随机森林 其他算法 特征选择算法 性能评估算法 自然语言处理 计算机视觉 推荐系统 强化学习 迁移学习 来源 入门文档 十大经典算法入门 Copyright © 2015-present airdb.            LastUpdated: 2020-01-12 05:24:59 "},"wiki/sort.html":{"url":"wiki/sort.html","title":"排序","keywords":"","body":"算法 排序 视频 | 手撕九大经典排序算法，看我就够了！ 七大排序 Copyright © 2015-present airdb.            LastUpdated: 2020-01-12 05:24:59 "},"wiki/thing.html":{"url":"wiki/thing.html","title":"机器学习文档","keywords":"","body":"机器学习文档 集成学习方法 决策树算法总结 https://mp.weixin.qq.com/s/tevVm0jlS6vZ3LCnczWD0w 集成学习原理总结 https://mp.weixin.qq.com/s/i_Y9r4PM-xVEQ7SncRfE_g 随机森林算法总结 https://mp.weixin.qq.com/s/bSNAN0Ki4xizKbseWzrSxg 随机森林算法参数解释及调优 https://mp.weixin.qq.com/s/hiyjuCWSCOzdF55DU5XkUw AdaBoost算法总结(一) https://mp.weixin.qq.com/s/Q4az1uFIEmjonKfu_eEmAQ AdaBoost算法总结(二) https://mp.weixin.qq.com/s/z34fVtc-4eI_b64JUF9_fg AdaBoost项目实战：参数择优与泛化能力 https://mp.weixin.qq.com/s/7MzoixbE8rt9Y6oTV4o0ig 梯度提升树算法原理小结 https://mp.weixin.qq.com/s/cRKkvicgFcYkSYQqrBIIpQ scikit-learn 梯度提升树(GBDT)算法实战 https://mp.weixin.qq.com/s/dS2kQ_JjHsvJyKWFrKd6aQ XGBoost算法原理小结 https://mp.weixin.qq.com/s/wDPu_nUYODwSRwJJa8nouw XGBoost之切分点算法 https://mp.weixin.qq.com/s/v9yF5KK2eVJOQ5UOYx4jPA 支持向量机 浅析感知机学习算法 https://mp.weixin.qq.com/s/PxL-glGrOI4glCQbwzSRXQ 支持向量机(一)：支持向量机的分类思想 https://mp.weixin.qq.com/s/cKQYk3817cnlWMVGLt8tLw 支持向量机(二)：算法详细解析 https://mp.weixin.qq.com/s/x2UGq0Zft0dxhFqfA6I1Lw 支持向量机(三)：图解KKT条件和拉格朗日乘子法 https://mp.weixin.qq.com/s/5V2Nx3c0ewTIoZtFkN0q2g 深入浅出核函数 https://mp.weixin.qq.com/s/fbuGqAfPo9uRSLctJSyDow 支持向量机：SMO算法剖析 https://mp.weixin.qq.com/s/s0d7ZoQOjtpWKlrfbVfVmA 支持向量机应用：人脸识别 https://mp.weixin.qq.com/s/g04ci5LfhL73XopcGLQv9g 线性回归与分类模型 线性回归：不能忽视的三个问题 https://mp.weixin.qq.com/s/cL7xzaofVsocqXc54eYP8g 深入理解线性回归算法(一) https://mp.weixin.qq.com/s/mMhhyvlbt2t6ypbU-JN9mg 深入理解线性回归算法(二)：正则项的详细分析 https://mp.weixin.qq.com/s/RJi6PKAfTSIkVrd8kNZDEw 线性分类模型(一)：线性判别模型分析 https://mp.weixin.qq.com/s/3Owz3z64kMDiHP9WLd6i2A 线性分类模型(二)：logistic回归模型分析 https://mp.weixin.qq.com/s/owT0BubsfAYpjmZZTAXblQ 比较全面的L1和L2正则化解释 https://mp.weixin.qq.com/s/OWQU9jM-ZItcy1antSwZxw 正则化方法小结 https://mp.weixin.qq.com/s/CDMBQPgzcrjbZ_sX01q2hQ 贝叶斯思想 浅谈频率学派和贝叶斯学派 https://mp.weixin.qq.com/s/wuHq99vDNzI0Lx3eIqXAbw 浅谈先验分布和后验分布 https://mp.weixin.qq.com/s/J6mBP8Fa6XOSITM1pXNN4w 贝叶斯分析：抛硬币的概率真的是1/2吗 https://mp.weixin.qq.com/s/qzklm0v6CsV4mYvLLlyWZw 机器学习基础与模型评估方法 从机器学习谈起 https://mp.weixin.qq.com/s/ahFjcIrsxNZ37USV-jFdEQ 机器学习概论 https://mp.weixin.qq.com/s/dB10CjlNVMkP6rYg7_CVSw 机器学习算法常用指标总结 https://mp.weixin.qq.com/s/u0sAIXYDC1_8JkvXu7_ozw 模型优化的风向标:偏差与方差 https://mp.weixin.qq.com/s/OvXcU7GO7Td8r8pWQ9NBNQ 机器学习模型评估方法 https://mp.weixin.qq.com/s/Vlxq2dd2q0QJdAjmSl0tQg 机器学习模型性能评估(一)：错误率与精度 https://mp.weixin.qq.com/s/Dq_87Lrd_KA63szbjFsnbQ 机器学习模型性能评估(二)：P-R曲线和ROC曲线 https://mp.weixin.qq.com/s/cr142o9DZ7KCYuxGPQNQRA 机器学习模型性能评估(三)：代价曲线 https://mp.weixin.qq.com/s/4RMrcYiZ7OGKLH5p6u3qnw 机器学习预处理 非参数性的正态检验 https://mp.weixin.qq.com/s/dcS-usNqPetmokFXc-oTvQ 偏度与峰度的正态性分布判断 https://mp.weixin.qq.com/s/VgwRuEIyvsC5K8dtgIjDuQ 基于Q-Q图的正态性分布 https://mp.weixin.qq.com/s/_UTKNcOgKQcCogk2C2tsQQ 神经网络 浅谈logistic函数和softmax函数 https://mp.weixin.qq.com/s/QHk0E9rdZ6wr5q8ZG00TnA 神经网络浅讲：从神经元到深度学习(一) https://mp.weixin.qq.com/s/neGvg57iWwVfrvoS60HXnQ 神经网络浅讲：从神经元到深度学习(二) https://mp.weixin.qq.com/s/fKpq-wxW2OJVFPfuBeewew 机器学习数学 常见的几种最优化方法 https://mp.weixin.qq.com/s/OTM6hapEWblwRQJJqyN-0Q 拉格朗日乘数法 https://mp.weixin.qq.com/s/PQXr5WZ8cnOLOGOOZCZcSg 为什么梯度是函数变化最快的方向 https://mp.weixin.qq.com/s/2E3LRtWPlxgpRRARVpWa_w 梯度下降法的三种形式BGD、SGD以及MBGD https://mp.weixin.qq.com/s/dWEQTSKn28ySKf8rs5hnmA 为什么要对数据进行归一化处理 https://mp.weixin.qq.com/s/3yGKW1DIAlzzrKCR0U9eag 机器学习中的相似性度量总结 https://mp.weixin.qq.com/s/I1ovA7e98sLZHX0RVihmyA K近邻算法 K近邻算法(KNN)原理小结 https://mp.weixin.qq.com/s/5EL3Q85v4Bo1ewnA-ZDbIQ 机器学习资源 来看看这20个顶尖的开源项目 https://mp.weixin.qq.com/s/yYBSDxGNa4VVs0HrNThM4A Copyright © 2015-present airdb.            LastUpdated: 2020-01-12 05:24:59 "},"wiki/machine-learning-with-go/":{"url":"wiki/machine-learning-with-go/","title":"Machine Learning With Go","keywords":"","body":"机器学习 -Go 翻译名 原名：Machine Learning With Go 译名：机器学习 - Go 翻译来源 Book: Machine Learning With Go PDF: Machine Learning With Go Github Source Code Bilibili Video 使用Go做机器学习 Copyright © 2015-present airdb.            LastUpdated: 2020-01-12 05:24:59 "},"wiki/machine-learning-with-go/table-of-contents.html":{"url":"wiki/machine-learning-with-go/table-of-contents.html","title":"Table of Contents","keywords":"","body":"目录 Table of Contents Preface [Page 18-30, 12] What this book covers What you need for this book Who this book is for Conventions Reader feedback Customer support Downloading the example code Downloading the color images of this book Errata Piracy Questions Chapter 01. Gathering and Organizing Data [Page 31-69, 38] Handling data - Gopher style Best practices for gathering and organizing data with Go CSV files Reading in CSV data from a file Handling unexpected fields Handling unexpected types Manipulating CSV data with data frames JSON Parsing JSON JSON output SQL-like databases Connecting to an SQL database Querying the database Modifying the database Caching Caching data in memory Caching data locally on disk Data versioning Pachyderm jargon Deploying/installing Pachyderm Creating data repositories for data versioning Putting data into data repositories Getting data out of versioned data repositories References Summary Chapter 2. Matrices, Probability, and Statistics [Page 70-105, 35] Matrices and vectors Vectors Vector operations Matrices Matrix operations Statistics Distributions Statistical measures Measures of central tendency Measures of spread or dispersion Visualizing distributions Histograms Box plotsProbabilityRandom variablesProbability measuresIndependent and conditional probabilityHypothesis testingTest statisticsCalculating p-valuesReferencesSummary Chapter 3. Evaluation and Validation [Page 105-131, 26] EvaluationContinuous metricsCategorical metricsIndividual evaluation metrics for categorical variablesConfusion matrices, AUC, and ROCValidationTraining and test setsHoldout setCross validationReferencesSummary Chapter 4. Regression [Page 132-165, 33] Understanding regression model jargonLinear regressionOverview of linear regressionLinear regression assumptions and pitfallsLinear regression example Profiling the dataChoosing our independent variableCreating our training and test setsTraining our modelEvaluating the trained modelMultiple linear regressionNonlinear and other types of regressionReferencesSummary Chapter 5. Classification [Page 166-205, 39] Understanding classification model jargonLogistic regressionOverview of logistic regressionLogistic regression assumptions and pitfallsLogistic regression exampleCleaning and profiling the dataCreating our training and test setsTraining and testing the logistic regression modelk-nearest neighborsOverview of kNNkNN assumptions and pitfallskNN exampleDecision trees and random forestsOverview of decision trees and random forestsDecision tree and random forest assumptions and pitfallsDecision tree exampleRandom forest exampleNaive bayesOverview of naive bayes and its big assumptionNaive bayes exampleReferencesSummary Chapter 6. Clustering [Page 206-234, 28] Understanding clustering model jargonMeasuring Distance or SimilarityEvaluating clustering techniquesInternal clustering evaluationExternal clustering evaluationk-means clusteringOverview of k-means clusteringk-means assumptions and pitfalls k-means clustering exampleProfiling the dataGenerating clusters with k-meansEvaluating the generated clustersOther clustering techniquesReferencesSummary Chapter 7. Time Series and Anomaly Detection [Page 235-267, 32] Representing time series data in GoUnderstanding time series jargonStatistics related to time seriesAutocorrelationPartial autocorrelationAuto-regressive models for forecastingAuto-regressive model overviewAuto-regressive model assumptions and pitfallsAuto-regressive model exampleTransforming to a stationary seriesAnalyzing the ACF and choosing an AR orderFitting and evaluating an AR(2) modelAuto-regressive moving averages and other time series modelsAnomaly detectionReferencesSummary Chapter 8. Neural Networks and Deep Learning [Page 268-301, 33] Understanding neural net jargonBuilding a simple neural networkNodes in the networkNetwork architectureWhy do we expect this architecture to work?Training our neural networkUtilizing the simple neural networkTraining the neural network on real dataEvaluating the neural networkIntroducing deep learningWhat is a deep learning model?Deep learning with GoSetting up TensorFlow for use with GoRetrieving and calling a pretrained TensorFlow modelObject detection using TensorFlow from GoReferences Summary Chapter 9. Deploying and Distributing Analyses and Models [Page 302-341, 39] Running models reliably on remote machinesA brief introduction to Docker and Docker jargonDocker-izing a machine learning applicationDocker-izing the model training and exportDocker-izing model predictionsTesting the Docker images locallyRunning the Docker images on remote machinesBuilding a scalable and reproducible machine learning pipelineSetting up a Pachyderm and Kubernetes clusterBuilding a Pachyderm machine learning pipelineCreating and filling the input repositoriesCreating and running the processing stagesUpdating pipelines and examining provenanceScaling pipeline stagesReferencesSummary Chapter 10. Algorithms/Techniques Related to Machine Learning [Page 342-351, 9] Gradient descentEntropy, information gain, and related methodsBackpropagation Copyright © 2015-present airdb.            LastUpdated: 2020-01-12 05:24:59 "},"wiki/machine-learning-with-go/chapter-02/":{"url":"wiki/machine-learning-with-go/chapter-02/","title":"Chapter 02 - 矩阵，概率和统计","keywords":"","body":"Matrices, Probability, and Statistics [Page 71-105, 34] Although we will take a mostly practical/applied approach to machine learningthroughout this book, certain fundamental topics are essential to understand andproperly apply machine learning. In particular, a fundamental understanding ofprobability and statistics will allow us to match certain algorithms with relevantproblems, understand our data and results, and apply necessary transformations toour data. Matrices and a little linear algebra will then allow us to properly representour data and implement optimizations, minimizations, and matrix-basedtransformations. Do not worry too much if you are a little rusty in math or statistics. We will cover afew of the basics here and show you how to programmatically work with the relevantstatistical measures and matrix techniques that will be utilized later in the book. Thatbeing said, this is not a book on statistics, probability, and linear algebra. To truly beproficient in machine learning, one should take time to learn these subjects on adeeper level. Copyright © 2015-present airdb.            LastUpdated: 2020-01-12 05:24:59 "},"tags.html":{"url":"tags.html","title":"tags","keywords":"","body":"Tags Copyright © 2015-present airdb.            LastUpdated: 2020-01-12 05:24:59 "}}